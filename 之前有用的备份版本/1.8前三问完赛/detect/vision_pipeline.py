import cv2
import numpy as np
import logging
import time
from typing import Dict, Optional, Tuple, List

from YOLO11_Detect_YUV420SP import VisionDetector
from cv_chuli import SquareRefinement, create_refinement_processor

# é…ç½®æ—¥å¿—
logger = logging.getLogger("VisionPipeline")

class VisionPipeline:
    """è§†è§‰å¤„ç†ç®¡é“ - çº¯YOLOæ£€æµ‹æ–¹æ¡ˆ"""
    
    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–è§†è§‰å¤„ç†ç®¡é“ - çº¯æ£€æµ‹æ¨¡å¼
        :param config: é…ç½®å­—å…¸
        """
        self.config = config
        
        # åˆå§‹åŒ–YOLOæ£€æµ‹å™¨
        logger.info("åˆå§‹åŒ–YOLO11æ£€æµ‹å™¨...")
        self.yolo_detector = VisionDetector(
            model_path=config['yolo']['model_path'],
            conf_thresh=config['yolo']['conf_thresh'],
            iou_thresh=config['yolo']['iou_thresh'],
            min_aspect_ratio=config['yolo'].get('min_aspect_ratio', 0.5),
            max_aspect_ratio=config['yolo'].get('max_aspect_ratio', 2.0)
        )
        
        # ç¦ç”¨OpenCVç²¾ç»†åŒ–å¤„ç†
        logger.info("OpenCVç²¾ç»†åŒ–å¤„ç†å·²ç¦ç”¨ - ä½¿ç”¨çº¯YOLOæ£€æµ‹æ–¹æ¡ˆ")
        self.opencv_processor = None
        
        # å¤„ç†æ¨¡å¼é…ç½® - å¼ºåˆ¶ä½¿ç”¨çº¯æ£€æµ‹æ¨¡å¼
        self.enable_opencv_refinement = False  # å¼ºåˆ¶ç¦ç”¨
        self.fallback_to_yolo = True
        
        # ä¸éœ€è¦æ‰©å±•æ£€æµ‹æ¡†
        self.bbox_expansion = 0
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_frames': 0,
            'yolo_detections': 0,
            'aspect_ratio_filtered': 0,
            'opencv_successes': 0,      # å§‹ç»ˆä¸º0
            'opencv_failures': 0,       # å§‹ç»ˆä¸º0
            'fallback_uses': 0,         # å§‹ç»ˆä¸º0
            'total_yolo_time': 0.0,
            'total_opencv_time': 0.0    # å§‹ç»ˆä¸º0
        }
        
        logger.info(f"çº¯YOLOæ£€æµ‹ç®¡é“åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"é•¿å®½æ¯”ç­›é€‰: {config['yolo'].get('min_aspect_ratio', 0.5):.1f} - {config['yolo'].get('max_aspect_ratio', 2.0):.1f}")
        logger.info(f"ğŸš€ æ€§èƒ½ä¼˜åŒ–: è·³è¿‡OpenCVå¤„ç†ï¼Œç›´æ¥ä½¿ç”¨YOLOæ£€æµ‹æ¡†ä¸­å¿ƒç‚¹")

    def process_frame(self, frame: np.ndarray, enable_debug: bool = False) -> Dict:
        """
        å¤„ç†å•å¸§å›¾åƒ - çº¯YOLOæ£€æµ‹æ–¹æ¡ˆ
        :param frame: è¾“å…¥å›¾åƒ
        :param enable_debug: æ˜¯å¦å¯ç”¨è°ƒè¯•ä¿¡æ¯ï¼ˆåœ¨çº¯æ£€æµ‹æ¨¡å¼ä¸‹åŸºæœ¬æ— ç”¨ï¼‰
        :return: å¤„ç†ç»“æœå­—å…¸
        """
        self.stats['total_frames'] += 1
        result = {
            'success': False,
            'center': None,
            'bbox': None,
            'confidence': 0.0,
            'method': 'pure_yolo',
            'yolo_result': None,
            'opencv_result': None,       # å§‹ç»ˆä¸ºNone
            'expanded_bbox': None,       # ä¸å†éœ€è¦
            'processing_time': {
                'yolo': 0.0,
                'opencv': 0.0,           # å§‹ç»ˆä¸º0
                'total': 0.0
            }
        }
        
        start_time = time.time()
        
        try:
            # çº¯YOLOæ£€æµ‹
            yolo_start = time.time()
            yolo_result = self.yolo_detector.get_best_detection(frame)
            yolo_time = time.time() - yolo_start
            
            self.stats['total_yolo_time'] += yolo_time
            result['processing_time']['yolo'] = yolo_time
            result['yolo_result'] = yolo_result
            
            if not yolo_result['found']:
                result['method'] = 'yolo_no_detection'
                result['processing_time']['total'] = time.time() - start_time
                return result
            
            self.stats['yolo_detections'] += 1
            
            # ç›´æ¥ä½¿ç”¨YOLOç»“æœï¼Œæ— éœ€OpenCVå¤„ç†
            result.update({
                'success': True,
                'center': yolo_result['center'],
                'bbox': yolo_result['bbox'],
                'confidence': yolo_result['confidence'],
                'method': 'pure_yolo_detection',
                'size': yolo_result.get('size', [0, 0]),
                'aspect_ratio': yolo_result.get('aspect_ratio', 0)
            })
            
            if enable_debug:
                logger.debug(f"çº¯YOLOæ£€æµ‹æˆåŠŸ: ä¸­å¿ƒç‚¹({yolo_result['center'][0]}, {yolo_result['center'][1]}), ç½®ä¿¡åº¦: {yolo_result['confidence']:.2f}")
            
            result['processing_time']['total'] = time.time() - start_time
            return result
            
        except Exception as e:
            logger.error(f"çº¯YOLOæ£€æµ‹å¤±è´¥: {e}")
            result.update({
                'method': 'error',
                'error': str(e),
                'processing_time': {'total': time.time() - start_time}
            })
            return result

    def get_processing_stats(self) -> Dict:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯ - çº¯æ£€æµ‹ç‰ˆæœ¬"""
        if self.stats['total_frames'] > 0:
            yolo_avg_time = (self.stats['total_yolo_time'] / self.stats['total_frames']) * 1000
            
            stats = {
                'total_frames': self.stats['total_frames'],
                'yolo_detection_rate': (self.stats['yolo_detections'] / self.stats['total_frames']) * 100,
                'aspect_ratio_filter_rate': (self.stats['aspect_ratio_filtered'] / max(self.stats['yolo_detections'], 1)) * 100,
                'opencv_success_rate': 0.0,    # å§‹ç»ˆä¸º0
                'opencv_failure_rate': 0.0,    # å§‹ç»ˆä¸º0
                'fallback_rate': 0.0,          # å§‹ç»ˆä¸º0
                'avg_yolo_time_ms': yolo_avg_time,
                'avg_opencv_time_ms': 0.0,     # å§‹ç»ˆä¸º0
                'total_processing_time_ms': yolo_avg_time  # åªæœ‰YOLOæ—¶é—´
            }
            return stats
        return {}

    def set_opencv_enabled(self, enabled: bool):
        """åŠ¨æ€å¯ç”¨/ç¦ç”¨OpenCVç²¾ç»†åŒ–å¤„ç† - åœ¨çº¯æ£€æµ‹æ¨¡å¼ä¸‹æ— æ•ˆ"""
        if enabled:
            logger.warning("çº¯YOLOæ£€æµ‹æ¨¡å¼ä¸‹æ— æ³•å¯ç”¨OpenCVç²¾ç»†åŒ–å¤„ç†")
        else:
            logger.info("OpenCVç²¾ç»†åŒ–å¤„ç†å·²ç¦ç”¨ï¼ˆçº¯æ£€æµ‹æ¨¡å¼ï¼‰")

    def visualize_result(self, frame: np.ndarray, result: Dict) -> np.ndarray:
        """
        å¯è§†åŒ–å¤„ç†ç»“æœ - çº¯YOLOç‰ˆæœ¬
        :param frame: åŸå§‹å›¾åƒ
        :param result: å¤„ç†ç»“æœ
        :return: å¯è§†åŒ–åçš„å›¾åƒ
        """
        if not result['success']:
            return frame
        
        vis_frame = frame.copy()
        
        try:
            # ç»˜åˆ¶YOLOæ£€æµ‹ç»“æœ
            center = result['center']
            bbox = result['bbox']
            method = result['method']
            
            # ä½¿ç”¨è“è‰²è¡¨ç¤ºçº¯YOLOæ£€æµ‹
            color = (255, 0, 0)  # è“è‰² - çº¯YOLOæ£€æµ‹
            thickness = 3
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(vis_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, thickness)
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            cv2.circle(vis_frame, tuple(center), 10, color, -1)
            cv2.circle(vis_frame, tuple(center), 15, color, 3)
            
            # ç»˜åˆ¶åå­—çº¿
            cv2.line(vis_frame, (center[0]-20, center[1]), (center[0]+20, center[1]), color, 3)
            cv2.line(vis_frame, (center[0], center[1]-20), (center[0], center[1]+20), color, 3)
            
            # æ˜¾ç¤ºç½®ä¿¡åº¦ä¿¡æ¯
            info_text = f"PURE YOLO: {result['confidence']:.2f}"
            cv2.putText(vis_frame, info_text, (bbox[0], bbox[1]-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            # æ˜¾ç¤ºå°ºå¯¸å’Œé•¿å®½æ¯”ä¿¡æ¯
            if 'size' in result and 'aspect_ratio' in result:
                size_text = f"Size: {result['size'][0]}x{result['size'][1]}, Ratio: {result['aspect_ratio']:.2f}"
                cv2.putText(vis_frame, size_text, (bbox[0], bbox[1]-35), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            
            # æ˜¾ç¤ºå¤„ç†æ—¶é—´ä¿¡æ¯
            time_info = result['processing_time']
            time_text = f"YOLO: {time_info['yolo']*1000:.1f}ms (Pure Detection)"
            cv2.putText(vis_frame, time_text, (10, vis_frame.shape[0]-30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # æ·»åŠ çº¯æ£€æµ‹æ¨¡å¼æ ‡è¯†
            mode_text = "PURE YOLO DETECTION MODE"
            cv2.putText(vis_frame, mode_text, (10, vis_frame.shape[0]-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
        except Exception as e:
            logger.error(f"å¯è§†åŒ–å¤±è´¥: {e}")
        
        return vis_frame

class VisionConfig:
    """è§†è§‰å¤„ç†é…ç½®ç®¡ç†å™¨ - çº¯æ£€æµ‹ç‰ˆæœ¬"""
    
    @staticmethod
    def create_default_config() -> Dict:
        """åˆ›å»ºé»˜è®¤è§†è§‰å¤„ç†é…ç½® - çº¯æ£€æµ‹æ¨¡å¼"""
        return {
            # YOLOé…ç½®
            'yolo': {
                'model_path': '/root/square/detect/2.0.bin',
                'conf_thresh': 0.25,
                'iou_thresh': 0.45,
                'min_aspect_ratio': 0.5,
                'max_aspect_ratio': 2.0
            },
            
            # OpenCVç²¾ç»†åŒ–é…ç½® - å·²ç¦ç”¨
            'opencv': {
                'min_contour_area': 300,
                'max_contour_area': 15000,
                'blur_kernel_size': 5,
                'morph_kernel_size': 3
            },
            
            # å¤„ç†æµç¨‹é…ç½® - çº¯æ£€æµ‹æ¨¡å¼
            'enable_opencv_refinement': False,  # å¼ºåˆ¶ç¦ç”¨
            'fallback_to_yolo': True,
            'bbox_expansion': 0,                # ä¸éœ€è¦æ‰©å±•
            
            # æ‘„åƒå¤´é…ç½®
            'camera': {
                'width': 640,
                'height': 480,
                'fps': 30
            }
        }
    
    @staticmethod
    def create_performance_config() -> Dict:
        """åˆ›å»ºæ€§èƒ½ä¼˜å…ˆé…ç½® - çº¯æ£€æµ‹æ¨¡å¼ï¼ˆä¸é»˜è®¤ç›¸åŒï¼‰"""
        return VisionConfig.create_default_config()
    
    @staticmethod
    def create_accuracy_config() -> Dict:
        """åˆ›å»ºç²¾åº¦ä¼˜å…ˆé…ç½® - çº¯æ£€æµ‹æ¨¡å¼ï¼ˆä¸é»˜è®¤ç›¸åŒï¼‰"""
        return VisionConfig.create_default_config()

if __name__ == "__main__":
    # è§†è§‰å¤„ç†ç®¡é“æµ‹è¯• - çº¯æ£€æµ‹ç‰ˆæœ¬
    import sys
    import time
    
    print("å¯åŠ¨çº¯YOLOæ£€æµ‹ç®¡é“æµ‹è¯•...")
    print("=" * 50)
    print("å¤„ç†æµç¨‹: YOLO11æ£€æµ‹ â†’ ç›´æ¥ä½¿ç”¨æ£€æµ‹æ¡†ä¸­å¿ƒç‚¹")
    print("ğŸš€ æ€§èƒ½ä¼˜åŒ–: è·³è¿‡OpenCVåå¤„ç†")
    print("=" * 50)
    
    try:
        # åˆ›å»ºé…ç½®
        config = VisionConfig.create_default_config()
        
        # åˆå§‹åŒ–è§†è§‰ç®¡é“
        pipeline = VisionPipeline(config)
        
        # è¿æ¥æ‘„åƒå¤´
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, config['camera']['width'])
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, config['camera']['height'])
        cap.set(cv2.CAP_PROP_FPS, config['camera']['fps'])
        
        print("\næŒ‰é”®è¯´æ˜:")
        print("'q' - é€€å‡º")
        print("'s' - æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡")
        print("'r' - é‡ç½®ç»Ÿè®¡")
        print("'v' - åˆ‡æ¢å¯è§†åŒ–æ˜¾ç¤º")
        
        show_visualization = True
        frame_count = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                print("æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                break
            
            frame_count += 1
            
            # å¤„ç†å¸§
            result = pipeline.process_frame(frame, enable_debug=(frame_count % 30 == 0))
            
            # å¯è§†åŒ–
            if show_visualization:
                vis_frame = pipeline.visualize_result(frame, result)
                
                # æ·»åŠ çŠ¶æ€ä¿¡æ¯
                status_text = f"Frame: {frame_count}, Method: {result['method']}"
                cv2.putText(vis_frame, status_text, (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                if result['success']:
                    center_text = f"Center: {result['center']}"
                    cv2.putText(vis_frame, center_text, (10, 60), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                cv2.imshow("Pure YOLO Detection Pipeline Test", vis_frame)
            
            # æ§åˆ¶å°è¾“å‡º
            if frame_count % 10 == 0:
                if result['success']:
                    center = result['center']
                    method = result['method']
                    total_time = result['processing_time']['total'] * 1000
                    print(f"\rå¸§{frame_count}: {method} -> ä¸­å¿ƒç‚¹({center[0]}, {center[1]}) è€—æ—¶{total_time:.1f}ms [çº¯æ£€æµ‹]", end="", flush=True)
                else:
                    print(f"\rå¸§{frame_count}: æœªæ£€æµ‹åˆ°ç›®æ ‡", end="", flush=True)
            
            # æŒ‰é”®å¤„ç†
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('v'):
                show_visualization = not show_visualization
                print(f"\nå¯è§†åŒ–æ˜¾ç¤º: {'å¼€å¯' if show_visualization else 'å…³é—­'}")
            elif key == ord('s'):
                stats = pipeline.get_processing_stats()
                if stats:
                    print("\n" + "="*60)
                    print("çº¯YOLOæ£€æµ‹ç»Ÿè®¡:")
                    for key, value in stats.items():
                        if 'rate' in key or 'time' in key:
                            print(f"  {key}: {value:.2f}")
                        else:
                            print(f"  {key}: {value}")
                    print("="*60)
            elif key == ord('r'):
                pipeline.reset_stats()
                frame_count = 0
                print("\nç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")

    except Exception as e:
        print(f"æµ‹è¯•ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    finally:
        try:
            if 'cap' in locals():
                cap.release()
            cv2.destroyAllWindows()
            
            # æœ€ç»ˆç»Ÿè®¡
            if 'pipeline' in locals():
                final_stats = pipeline.get_processing_stats()
                if final_stats:
                    print("\n" + "="*60)
                    print("æœ€ç»ˆçº¯YOLOæ£€æµ‹ç»Ÿè®¡:")
                    for key, value in final_stats.items():
                        if 'rate' in key or 'time' in key:
                            print(f"  {key}: {value:.2f}")
                        else:
                            print(f"  {key}: {value}")
                    print("="*60)
            
            print("çº¯æ£€æµ‹æµ‹è¯•å®Œæˆ")
        except:
            pass
